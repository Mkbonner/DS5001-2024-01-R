{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Entropy and Peplexity\n",
    "\n",
    "```yaml\n",
    "Course:  DS 5001\n",
    "Module:  03 Lab\n",
    "Topic:   Entropy and Peplexity\n",
    "Author:  R.C. Alvarado\n",
    "```\n",
    "\n",
    "**Purpose**: Clarify concept of perplexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Overview\n",
    "\n",
    "**Entropy** $H$ is the expectation of information in a distribution.\n",
    "\n",
    "**Self-entropy** $h$ is the information of an event.\n",
    "\n",
    "**Information** $i$ is log normalized surprise of an event.\n",
    "\n",
    "**Surprise** $s$ is just the inverse probability on an event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Probability $p$\n",
    "\n",
    "$\\Large p = \\frac{n}{N}$\n",
    "\n",
    "$p(w) = \\Large\\frac{n_w}{N_{corpus}}$ \n",
    "\n",
    "`p = n / n.sum()`\n",
    "\n",
    "Most terms have low probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Surprise $s$\n",
    "\n",
    "$\\Large s = \\Large\\frac{1}{p}$\n",
    "\n",
    "$s(w) = p(w)^{-1}$\n",
    "\n",
    "Surrprise $s$ increases as the inverse of $p$. \n",
    "\n",
    "Note how inverting $p$ adds variance to the long tail; \\\n",
    "the curve now looks like a simple quadratic. \n",
    "\n",
    "We can see a more gradual increase in surprise as terms become more rare.\n",
    "\n",
    "<!-- V.s.value_counts().plot(style='*-') -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Information $i$\n",
    "\n",
    "$\\Large i= log_2(s)$\n",
    "\n",
    "$i(w) = log_2(s(w))$\n",
    "\n",
    "As normalized suprise, information now has a long tail structure. \n",
    "\n",
    "But notice also the range of information -- it is between 1 and 18. \n",
    "\n",
    "What does this correspond to?\n",
    "\n",
    "<!-- V.i.value_counts().plot(style='*-'); -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Entropy $h$ and $H$\n",
    "\n",
    "**Self-entropy $h$** \n",
    "\n",
    "$\\Large h = p i$\n",
    "\n",
    "$h(w) = p(w)i(w)$\n",
    "\n",
    "**Entropy $H$**\n",
    "\n",
    "$H = \\Sigma p i = \\mathbb{E}[I]$\n",
    "\n",
    "For the self-entropy of each term, we multiply $p$ and $i$. \n",
    "\n",
    "When summed, this will give us the expectation of the information in the distribution, i.e. it's entropy.\n",
    "\n",
    "<!-- V.h.value_counts().plot(style='*-'); -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Cross Entropy\n",
    "\n",
    "Token sequences: $ W = W_1^N = (w_1, w_2 ... w_N)$ \\\n",
    "True distribution: $ p = p(W) $ \\\n",
    "Model distribution: $ q = q(W) $\n",
    "\n",
    "$ H(p, q) = - \\sum_{x}^{} p(x) log_2(q(x)) $ \n",
    "\n",
    "$ H(p, q) = \\sum_{x}^{} p(x) log_2(\\frac{1}{q(x)}) $ \n",
    "\n",
    "$ i_q(x) = log_2(\\frac{1}{q(x)}) $\n",
    "\n",
    "$ H(p, q) = \\sum_{x} p(x) i_q(x) $ \n",
    "\n",
    "$ H(p, q) = \\vec{p} \\cdot \\vec{i_q} $\n",
    "\n",
    "## Cross Entropy relative to MaxEnt\n",
    "\n",
    "$ N = C(X) = \\sum_i c(x) $\n",
    "\n",
    "$ p_{u} = \\frac{1}{N} $ \n",
    "\n",
    "$ H_{cross} = H(p_u, q) $\n",
    "\n",
    "$ H_{cross} = \\sum_{x} \\frac{1}{N} i_q(x) $\n",
    "\n",
    "$ H_{cross} = \\frac{1}{N} \\sum_{x} i_q(x) $\n",
    "\n",
    "$ H_{cross} = \\frac{\\sum_x i_q(x)}{N} = mean(\\vec{i}) $\n",
    "\n",
    "<!--\n",
    "$ H_{cross} = \\frac{ |\\vec{i}|_1 }{ N } $\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity $PP$\n",
    "\n",
    "Perplexity is just the exponentation of entropy.\n",
    "\n",
    "In text analytics, the word typically refers to the expontation of cross-entropy.\n",
    "\n",
    "$\\Large PP = \\Large 2^{H}$\n",
    "\n",
    "$\\Large PP_{cross} = \\Large 2^{mean(\\vec{i})}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "c3b963de08c47c3b6758389c5e0978ad73698a111eb508d4e16b558edb8f4cbf"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
